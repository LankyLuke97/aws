<h2>Topic du Jour - the A* Pathfinding Algorithm</h2>
<p>Over the last few months, I feel that I've become quite solid with various graph-based algorithms, whether it's the various search algorithms, Prim's, Kruskal's, or Kahn's. There's still plenty to learn - like Ford Fulkerson's maximum flow algorithm - but it seems to me that there's a glaring gap in the shape of an A. And an asterix. It's the A* algorithm, I can never remember the details.  </p>
<p>I've seen massive success with some types of study using flash cards, but this doesn't transfer quite as immediately to longer form, more complex items like implementing an algorithm. It can certainly help, if done correctly, but really the best approach is to do it yourself.  </p>
<h2>Doing it myself - the theory</h2>
<p>Let's start with a few definitions so that I don't have to caveat the entirety of this piece. Although all of my work in this case was done on a grid, this can just as easily be considered a graph, where each node (or square) is connected to the nodes (or squares) around it. In my case, I have chosen to treat the nodes as being diagonally connected as well as along the cartesian grid. I am going to use the terms grid and graph interchangeably, as will I the terms node and square.  </p>
<p>In a graph, you connect nodes. If you don't, then you don't really have a graph. Ok, you still technically do, but I would question a) what use that graph is and b) your sanity.  </p>
<p>So, weights. I'm going to keep this simple for myself and treat the weights as an inherent characteristic of a node. That is to say, rather than assigning a weight to the trip from node A to node C and a different weight from node B to node C, I will instead say that node C has a weight that it costs to move to, regardless of which other node one is coming from. This doesn't have an effect on my understanding of the algorithm, but it does simplify some things for now.  </p>
<p>I started with just a basic implementation, without particularly focusing on performance. The core of the A<em> algorithm is a miniumum heap of some kind, tracking what's known as the f-score. The f-score is the weight, or distance, or time, or whatever flavour you have assigned to your graph, that it has so far cost to reach a given node, </em>plus the estimated cost from that node to your target node<em>. How do you estimate this, given that we probably wouldn't need the algorithm at all if we already knew the cost to reach our target from some arbitrary node? You need some sort of heuristic, or rule of thumb, that is </em>admissible<em> and, ideally though not strictly necessarily, </em>consistent*.  </p>
<p>It seems to me that the term <em>admissible heuristic</em> might be solely in use for this particular algorithm. It refers to a heuristic that never overestimates the actual cost of reaching the goal. That's it, pretty simple, though we'll come back to the implementation.  </p>
<p>A <em>consistent heuristic</em> is slightly more involved, but it essentially says that the heuristic for the cost to reach the goal from the current node must always be less than or equal to the cost to reach the goal from any neighbouring nodes once you include the cost of moving to that node. So, if I'm arbitrarily at node A, nieghbour of B, with an estimated cost to reach node C, <strong>h(A)</strong>, of 10 and a cost to move to node B, <strong>AB</strong> of 3, then the heuristic must say that the cost to reach C from B, <strong>h(B)</strong> is at <em>least</em> 7 - since then you have <strong>h(B)</strong> + <strong>AB</strong> &lt;= <strong>h(A)</strong>. That makes sense to me, God knows how it will look when I read it back tomorrow.  </p>
<p>Back to the f-score. As stated above, there are two parts: the heuristic, and the current lowest score to reach the given node; this latter value is known as the g_score, and we'll track it with a dictionary (or map, or hash, or whatever your language of choice might term it). I could choose whatever value or function I like for the heuristic, provided it meets the criteria of admissibility. Since I know that the domain is a square-based grid and that all neighbours can be reached at all times, a reasonable heuristic is simply the Hamming distance from the current grid coordinate to the end goal. (This is actually not admissibile once the path can go diagonally, but thanks to the way the weights are set up in this case, it almost always is. I only realised later on that this needed to change, but for now let's roll with it.)  </p>
<p>Ok, so we have our f-score. We store the f-score for each node in a min-heap, along with the node it's associated with. The algorithm then runs as follows:<br />
1. Pop the te with the minimum f-score from the heap.
2. For all neighbours of this node:
    1. Calculate a tenative g-score, which is the cost to travel from this node to the neighbour.
    2. Compare the tentative g-score to the stored g-score for that neighbour.
    3. If the tentative g-score is lower than the stored, update the backpointers dictionary for the neighbour to point to the current node, update the stored g-score for the neighbour to the tentative g-score, and add the neighbour, along with its freshly calculated f-score, to the min-heap.
3. Repeat until the goal is reached and the minimum-heap is not empty.  </p>
<p>That's it. Not all that difficult after all.  </p>
<p>The next thing I wanted to do was to visualise the path-finding in some way. Each year, I take part (badly) in Advent of Code, and I love seeing the visualisations that people come up with; I thought something similar here would be appropriate. I decided on a basic approach of writing a png file for each step of the algorithm; I used greyscale to represent the difficulty of moving into a grid square (normalising over the difficulties for all grid squares), with black being the easiest and white the hardest. Then, the current node being searched is coloured in blue, and all previously searched nodes are coloured red. Once the shortest path is found, a quick animation shows it clearly. The various png files are stored in a subfolder and compiled into a gif; if there are too many images to do so (because I didn't look into how to add more than a thousand files to a gif at which point the library and approach I'm using to do so start complaining about too many files), I switch to using <strong>ffmpeg</strong> to convert to an mp4. There's a lot to improve with this approach, but I just picked the thing that would get a visualistaion on screen the fastest.    </p>
<p><img alt="Gif of A* algorithm" src="videos/path_shorter.gif" /></p>
<p><img alt="MP4 of A* algorithm" src="videos/path_larger.mp4" /></p>
<h2>Improvements</h2>